{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Impute Missing Values**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will practice essential data wrangling techniques using the Stack Overflow survey dataset. The primary focus is on handling missing data and ensuring data quality. You will:\n",
    "\n",
    "- **Load the Data:** Import the dataset into a DataFrame using the pandas library.\n",
    "\n",
    "- **Clean the Data:** Identify and remove duplicate entries to maintain data integrity.\n",
    "\n",
    "- **Handle Missing Values:** Detect missing values, impute them with appropriate strategies, and verify the imputation to create a complete and reliable dataset for analysis.\n",
    "\n",
    "This lab equips you with the skills to effectively preprocess and clean real-world datasets, a crucial step in any data analysis project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Identify missing values in the dataset.\n",
    "\n",
    "-   Apply techniques to impute missing values in the dataset.\n",
    "  \n",
    "-   Use suitable techniques to normalize data in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install needed library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m108.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, numpy, pandas\n",
      "Successfully installed numpy-2.2.1 pandas-2.2.3 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load the Dataset Into a Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read Data**\n",
    "<p>\n",
    "The functions below will download the dataset into your browser:\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResponseId                      MainBranch                 Age  \\\n",
      "0           1  I am a developer by profession  Under 18 years old   \n",
      "1           2  I am a developer by profession     35-44 years old   \n",
      "2           3  I am a developer by profession     45-54 years old   \n",
      "3           4           I am learning to code     18-24 years old   \n",
      "4           5  I am a developer by profession     18-24 years old   \n",
      "\n",
      "            Employment RemoteWork   Check  \\\n",
      "0  Employed, full-time     Remote  Apples   \n",
      "1  Employed, full-time     Remote  Apples   \n",
      "2  Employed, full-time     Remote  Apples   \n",
      "3   Student, full-time        NaN  Apples   \n",
      "4   Student, full-time        NaN  Apples   \n",
      "\n",
      "                                    CodingActivities  \\\n",
      "0                                              Hobby   \n",
      "1  Hobby;Contribute to open-source projects;Other...   \n",
      "2  Hobby;Contribute to open-source projects;Other...   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                             EdLevel  \\\n",
      "0                          Primary/elementary school   \n",
      "1       Bachelor’s degree (B.A., B.S., B.Eng., etc.)   \n",
      "2    Master’s degree (M.A., M.S., M.Eng., MBA, etc.)   \n",
      "3  Some college/university study without earning ...   \n",
      "4  Secondary school (e.g. American high school, G...   \n",
      "\n",
      "                                           LearnCode  \\\n",
      "0                             Books / Physical media   \n",
      "1  Books / Physical media;Colleague;On the job tr...   \n",
      "2  Books / Physical media;Colleague;On the job tr...   \n",
      "3  Other online resources (e.g., videos, blogs, f...   \n",
      "4  Other online resources (e.g., videos, blogs, f...   \n",
      "\n",
      "                                     LearnCodeOnline  ... JobSatPoints_6  \\\n",
      "0                                                NaN  ...            NaN   \n",
      "1  Technical documentation;Blogs;Books;Written Tu...  ...            0.0   \n",
      "2  Technical documentation;Blogs;Books;Written Tu...  ...            NaN   \n",
      "3  Stack Overflow;How-to videos;Interactive tutorial  ...            NaN   \n",
      "4  Technical documentation;Blogs;Written Tutorial...  ...            NaN   \n",
      "\n",
      "  JobSatPoints_7 JobSatPoints_8 JobSatPoints_9 JobSatPoints_10  \\\n",
      "0            NaN            NaN            NaN             NaN   \n",
      "1            0.0            0.0            0.0             0.0   \n",
      "2            NaN            NaN            NaN             NaN   \n",
      "3            NaN            NaN            NaN             NaN   \n",
      "4            NaN            NaN            NaN             NaN   \n",
      "\n",
      "  JobSatPoints_11           SurveyLength SurveyEase ConvertedCompYearly JobSat  \n",
      "0             NaN                    NaN        NaN                 NaN    NaN  \n",
      "1             0.0                    NaN        NaN                 NaN    NaN  \n",
      "2             NaN  Appropriate in length       Easy                 NaN    NaN  \n",
      "3             NaN               Too long       Easy                 NaN    NaN  \n",
      "4             NaN              Too short       Easy                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/n01PQ9pSmiRX6520flujwQ/survey-data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows to ensure it loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Finding and Removing Duplicates\n",
    "##### Task 1: Identify duplicate rows in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 487\n",
      "\n",
      "Duplicate rows:\n",
      "       ResponseId                                         MainBranch  \\\n",
      "46264       46265                     I am a developer by profession   \n",
      "46774       46775                     I am a developer by profession   \n",
      "46921       46922                     I am a developer by profession   \n",
      "47073       47074  I am not primarily a developer, but I write co...   \n",
      "47340       47341                        I code primarily as a hobby   \n",
      "\n",
      "                      Age           Employment  \\\n",
      "46264     25-34 years old  Employed, full-time   \n",
      "46774     18-24 years old  Employed, full-time   \n",
      "46921     18-24 years old  Employed, full-time   \n",
      "47073     25-34 years old  Employed, full-time   \n",
      "47340  Under 18 years old   Student, full-time   \n",
      "\n",
      "                                 RemoteWork   Check  \\\n",
      "46264                                Remote  Apples   \n",
      "46774  Hybrid (some remote, some in-person)  Apples   \n",
      "46921                             In-person  Apples   \n",
      "47073                             In-person  Apples   \n",
      "47340                                   NaN  Apples   \n",
      "\n",
      "                                        CodingActivities EdLevel LearnCode  \\\n",
      "46264                                                NaN     NaN       NaN   \n",
      "46774  Hobby;Professional development or self-paced l...     NaN       NaN   \n",
      "46921                                                NaN     NaN       NaN   \n",
      "47073                                                NaN     NaN       NaN   \n",
      "47340                                                NaN     NaN       NaN   \n",
      "\n",
      "      LearnCodeOnline  ... JobSatPoints_6 JobSatPoints_7 JobSatPoints_8  \\\n",
      "46264             NaN  ...            NaN            NaN            NaN   \n",
      "46774             NaN  ...            NaN            NaN            NaN   \n",
      "46921             NaN  ...            NaN            NaN            NaN   \n",
      "47073             NaN  ...            NaN            NaN            NaN   \n",
      "47340             NaN  ...            NaN            NaN            NaN   \n",
      "\n",
      "      JobSatPoints_9 JobSatPoints_10 JobSatPoints_11 SurveyLength SurveyEase  \\\n",
      "46264            NaN             NaN             NaN          NaN        NaN   \n",
      "46774            NaN             NaN             NaN          NaN        NaN   \n",
      "46921            NaN             NaN             NaN          NaN        NaN   \n",
      "47073            NaN             NaN             NaN          NaN        NaN   \n",
      "47340            NaN             NaN             NaN          NaN        NaN   \n",
      "\n",
      "      ConvertedCompYearly JobSat  \n",
      "46264                 NaN    NaN  \n",
      "46774                 NaN    NaN  \n",
      "46921                 NaN    NaN  \n",
      "47073                 NaN    NaN  \n",
      "47340                 NaN    NaN  \n",
      "\n",
      "[5 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "duplicate_rows = df[df.duplicated(subset=df.columns.difference(['ResponseId']))]\n",
    "duplicate_count = duplicate_rows.shape[0]\n",
    "# Identify Duplicate Rows\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_count}\")\n",
    "\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(duplicate_rows.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 2: Remove the duplicate rows from the dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before duplicate removal: 65437\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows before duplicate removal:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "df.drop_duplicates(subset=df.columns.difference(['ResponseId']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after duplicate removal: 64950\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows after duplicate removal:\", df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Finding Missing Values\n",
    "##### Task 3: Find the missing values for all columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing items is:\n",
      "  ResponseId                 0\n",
      "MainBranch                 0\n",
      "Age                        0\n",
      "Employment                 0\n",
      "RemoteWork             10546\n",
      "                       ...  \n",
      "JobSatPoints_11        35505\n",
      "SurveyLength            8768\n",
      "SurveyEase              8712\n",
      "ConvertedCompYearly    41515\n",
      "JobSat                 35824\n",
      "Length: 114, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "missing_values = df.isnull().sum()\n",
    "print('The number of missing items is:\\n ', missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 4: Find out how many rows are missing in the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of missing rows in the RemoteWork Column is: 10546\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "remotework_missing = df[\"RemoteWork\"].isnull().sum()\n",
    "print('the number of missing rows in the RemoteWork Column is:', remotework_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Imputing Missing Values\n",
    "##### Task 5: Find the value counts for the column RemoteWork.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of values in the RemoteWork column is:\n",
      " RemoteWork\n",
      "Hybrid (some remote, some in-person)    22850\n",
      "Remote                                  20732\n",
      "In-person                               10822\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "remotework_values = df['RemoteWork'].value_counts()\n",
    "print('The number of values in the RemoteWork column is:\\n', remotework_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 6: Identify the most frequent (majority) value in the RemoteWork column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent value in the RemoteWork colunn is: 0    Hybrid (some remote, some in-person)\n",
      "Name: RemoteWork, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "mostfreq_value = df['RemoteWork'].mode()\n",
    "print('The most frequent value in the RemoteWork colunn is:', mostfreq_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 7: Impute (replace) all the empty rows in the column RemoteWork with the majority value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "df['RemoteWork'].fillna(mostfreq_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 8: Check for any compensation-related columns and describe their distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ResponseId', 'MainBranch', 'Age', 'Employment', 'RemoteWork', 'Check', 'CodingActivities', 'EdLevel', 'LearnCode', 'LearnCodeOnline', 'TechDoc', 'YearsCode', 'YearsCodePro', 'DevType', 'OrgSize', 'PurchaseInfluence', 'BuyNewTool', 'BuildvsBuy', 'TechEndorse', 'Country', 'Currency', 'CompTotal', 'LanguageHaveWorkedWith', 'LanguageWantToWorkWith', 'LanguageAdmired', 'DatabaseHaveWorkedWith', 'DatabaseWantToWorkWith', 'DatabaseAdmired', 'PlatformHaveWorkedWith', 'PlatformWantToWorkWith', 'PlatformAdmired', 'WebframeHaveWorkedWith', 'WebframeWantToWorkWith', 'WebframeAdmired', 'EmbeddedHaveWorkedWith', 'EmbeddedWantToWorkWith', 'EmbeddedAdmired', 'MiscTechHaveWorkedWith', 'MiscTechWantToWorkWith', 'MiscTechAdmired', 'ToolsTechHaveWorkedWith', 'ToolsTechWantToWorkWith', 'ToolsTechAdmired', 'NEWCollabToolsHaveWorkedWith', 'NEWCollabToolsWantToWorkWith', 'NEWCollabToolsAdmired', 'OpSysPersonal use', 'OpSysProfessional use', 'OfficeStackAsyncHaveWorkedWith', 'OfficeStackAsyncWantToWorkWith', 'OfficeStackAsyncAdmired', 'OfficeStackSyncHaveWorkedWith', 'OfficeStackSyncWantToWorkWith', 'OfficeStackSyncAdmired', 'AISearchDevHaveWorkedWith', 'AISearchDevWantToWorkWith', 'AISearchDevAdmired', 'NEWSOSites', 'SOVisitFreq', 'SOAccount', 'SOPartFreq', 'SOHow', 'SOComm', 'AISelect', 'AISent', 'AIBen', 'AIAcc', 'AIComplex', 'AIToolCurrently Using', 'AIToolInterested in Using', 'AIToolNot interested in Using', 'AINextMuch more integrated', 'AINextNo change', 'AINextMore integrated', 'AINextLess integrated', 'AINextMuch less integrated', 'AIThreat', 'AIEthics', 'AIChallenges', 'TBranch', 'ICorPM', 'WorkExp', 'Knowledge_1', 'Knowledge_2', 'Knowledge_3', 'Knowledge_4', 'Knowledge_5', 'Knowledge_6', 'Knowledge_7', 'Knowledge_8', 'Knowledge_9', 'Frequency_1', 'Frequency_2', 'Frequency_3', 'TimeSearching', 'TimeAnswering', 'Frustration', 'ProfessionalTech', 'ProfessionalCloud', 'ProfessionalQuestion', 'Industry', 'JobSatPoints_1', 'JobSatPoints_4', 'JobSatPoints_5', 'JobSatPoints_6', 'JobSatPoints_7', 'JobSatPoints_8', 'JobSatPoints_9', 'JobSatPoints_10', 'JobSatPoints_11', 'SurveyLength', 'SurveyEase', 'ConvertedCompYearly', 'JobSat']\n"
     ]
    }
   ],
   "source": [
    "## Write your code here\n",
    "column_headers = df.columns.tolist()\n",
    "print(column_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The values of the CompTotal column are: CompTotal\n",
      "100000.0    939\n",
      "60000.0     839\n",
      "120000.0    793\n",
      "80000.0     728\n",
      "50000.0     705\n",
      "           ... \n",
      "201600.0      1\n",
      "1100.0        1\n",
      "133600.0      1\n",
      "301210.0      1\n",
      "81920.0       1\n",
      "Name: count, Length: 3337, dtype: int64\n",
      "The values of the ConvertedCompYearly column are: ConvertedCompYearly\n",
      "64444.0     321\n",
      "53703.0     308\n",
      "75184.0     230\n",
      "85925.0     226\n",
      "107406.0    208\n",
      "           ... \n",
      "9711.0        1\n",
      "950000.0      1\n",
      "51448.0       1\n",
      "447569.0      1\n",
      "4738.0        1\n",
      "Name: count, Length: 6113, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "comptotal = df['CompTotal'].value_counts()\n",
    "yearly_comptotal = df['ConvertedCompYearly'].value_counts()\n",
    "print('The values of the CompTotal column are:', comptotal)\n",
    "print('The values of the ConvertedCompYearly column are:', yearly_comptotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this lab, you focused on imputing missing values in the dataset.**\n",
    "\n",
    "- Use the <code>pandas.read_csv()</code> function to load a dataset from a CSV file into a DataFrame.\n",
    "\n",
    "- Download the dataset if it's not available online and specify the correct file path.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
    "|-|-|-|-|\n",
    "|2024-11-05|1.3|Madhusudhan Moole|Updated lab|\n",
    "|2024-10-29|1.2|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-27|1.1|Madhusudhan Moole|Updated lab|\n",
    "|2024-09-26|1.0|Raghul Ramesh|Created lab|\n",
    "--!>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "prev_pub_hash": "70ab641719bca2be0bdcb38f6a8b5de7851b6e9c28d41b9407096c62e74916a6"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
